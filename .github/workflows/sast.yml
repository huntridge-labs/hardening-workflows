name: SAST Security Analysis

on:
  push:
    branches: [ main, develop ]
  pull_request:
    branches: [ main, develop ]
  # Commented out daily schedule to reduce noise - re-enable as needed
  # schedule:
  #   # Run SAST scan daily at 2 AM UTC
  #   - cron: '0 2 * * *'
  workflow_dispatch:
  workflow_call:

permissions:
  contents: read
  security-events: write
  actions: read
  pull-requests: write

env:
  PYTHON_VERSION: '3.12'

jobs:
  codeql-analysis:
    name: CodeQL Analysis
    runs-on: ubuntu-latest
    timeout-minutes: 45
    continue-on-error: true  # Allow pipeline to continue even if security issues found
    # Skip CodeQL in Act - it requires GitHub's infrastructure
    if: github.actor != 'nektos/act'
    permissions:
      actions: read
      contents: read
      security-events: write

    strategy:
      fail-fast: false
      matrix:
        language: [ 'python', 'javascript' ]

    steps:
    - name: Checkout repository
      uses: actions/checkout@v5

    - name: Initialize CodeQL
      uses: github/codeql-action/init@v3
      with:
        languages: ${{ matrix.language }}
        config-file: ./.github/codeql/codeql-config.yml

    - name: Debug - Show files to analyze
      run: |
        echo "🔍 Files that will be analyzed for ${{ matrix.language }}:"
        if [ "${{ matrix.language }}" = "javascript" ]; then
          echo "JavaScript/TypeScript files:"
          find . -name "*.js" -o -name "*.ts" -o -name "*.jsx" -o -name "*.tsx" | head -20
          echo "Package.json files:"
          find . -name "package.json"
        elif [ "${{ matrix.language }}" = "python" ]; then
          echo "Python files:"
          find . -name "*.py" | head -20
        fi

    - name: Set up Python
      if: matrix.language == 'python'
      uses: actions/setup-python@v4
      with:
        python-version: ${{ env.PYTHON_VERSION }}

    - name: Set up Node.js
      if: matrix.language == 'javascript'
      uses: actions/setup-node@v5
      with:
        node-version: '20'
        cache: 'npm'

    - name: Install Python dependencies
      if: matrix.language == 'python'
      run: |
        python -m pip install --upgrade pip
        # Install dependencies from all requirements files
        find . -name "requirements.txt" -exec pip install -r {} \;
        # Install additional dependencies for Lambda functions
        pip install boto3 botocore

    - name: Install Node.js dependencies
      if: matrix.language == 'javascript'
      run: |
        echo "📦 Setting up JavaScript environment..."
        if [ -f "package.json" ]; then
          echo "Found package.json, installing dependencies..."
          # Try npm ci first, fall back to npm install if lock file is out of sync
          if ! npm ci --ignore-engines; then
            echo "⚠️ npm ci failed, trying npm install to update lock file..."
            npm install --ignore-engines
          fi
          echo "✅ Dependencies installed"
        else
          echo "⚠️ No package.json found, skipping dependency installation"
        fi
        echo "JavaScript files in workspace:"
        find . -name "*.js" -type f | grep -v node_modules | head -10

    - name: Autobuild
      uses: github/codeql-action/autobuild@v3

    - name: Perform CodeQL Analysis
      uses: github/codeql-action/analyze@v3
      with:
        category: "/language:${{matrix.language}}"
      continue-on-error: true  # Don't fail if Code Security is not enabled

  opengrep-analysis:
    name: OpenGrep SAST
    runs-on: ubuntu-latest
    timeout-minutes: 20
    continue-on-error: true  # Allow pipeline to continue even if security issues found

    steps:
    - name: Checkout repository
      uses: actions/checkout@v5

    - name: Set up Python
      uses: actions/setup-python@v4
      with:
        python-version: ${{ env.PYTHON_VERSION }}

    - name: Install OpenGrep/Semgrep
      run: |
        # Use pip to install semgrep (more reliable than direct binary)
        python -m pip install --upgrade pip
        pip install semgrep

    - name: Run OpenGrep/Semgrep Security Analysis
      run: |
        echo "🔍 Running Semgrep comprehensive security analysis..."
        mkdir -p opengrep-reports
        # Run Semgrep with comprehensive scanning
        semgrep --config=auto --sarif --output=opengrep-reports/opengrep.sarif . || true
        semgrep --config=auto --json --output=opengrep-reports/opengrep.json . || true
        semgrep --config=auto --text --output=opengrep-reports/opengrep.txt . || true

        # Move files to root for artifact upload
        cp opengrep-reports/* . 2>/dev/null || true
      continue-on-error: true  # Continue even if security issues are found
      # Note: Semgrep provides all security rules for free, no paywalls

    - name: Check Code Security Status
      id: check-security
      run: |
        echo "🔍 Checking if GitHub Code Security is enabled..."
        # This will help users understand why SARIF upload might fail
        echo "ℹ️  Note: SARIF upload requires GitHub Advanced Security to be enabled"
        echo "ℹ️  If upload fails, security results will still be available as artifacts"

    - name: Upload SARIF file
      uses: github/codeql-action/upload-sarif@v3
      with:
        sarif_file: opengrep.sarif
      if: always() && github.actor != 'nektos/act' && hashFiles('opengrep.sarif') != ''
      continue-on-error: true  # Don't fail if Code Security is not enabled

    - name: Upload OpenGrep artifacts
      uses: actions/upload-artifact@v4
      with:
        name: opengrep-reports
        path: |
          opengrep.json
          opengrep.txt
          opengrep-reports/
        retention-days: 30
      if: always()

  bandit-analysis:
    name: Bandit Python Security
    runs-on: ubuntu-latest
    timeout-minutes: 15
    continue-on-error: true  # Allow pipeline to continue even if security issues found

    steps:
    - name: Checkout repository
      uses: actions/checkout@v5

    - name: Set up Python
      uses: actions/setup-python@v4
      with:
        python-version: ${{ env.PYTHON_VERSION }}

    - name: Install Bandit
      run: |
        python -m pip install --upgrade pip
        pip install bandit[toml]

    - name: Run Bandit Security Scan
      run: |
        echo "🔍 Running Bandit Python security analysis..."
        mkdir -p bandit-reports

        # Generate reports with explicit output verification, using pyproject.toml for exclusions
        echo "Generating SARIF report..."
        bandit -r . --exclude .husky,.github -f sarif -o bandit-reports/bandit-report.sarif || true

        echo "Generating JSON report..."
        bandit -r . --exclude .husky,.github -f json -o bandit-reports/bandit-report.json || true

        echo "Generating text report..."
        bandit -r . --exclude .husky,.github -f txt -o bandit-reports/bandit-report.txt || true

        # Copy and verify files
        cp bandit-reports/* . 2>/dev/null || true

        echo "Generated Bandit files:"
        ls -la bandit-reports/

        # Show file sizes to verify content
        for f in bandit-reports/*; do
          if [ -f "$f" ]; then
            echo "File: $f - Size: $(wc -c < "$f") bytes"
          fi
        done
      continue-on-error: true

    - name: Upload Bandit SARIF
      uses: github/codeql-action/upload-sarif@v3
      with:
        sarif_file: bandit-report.sarif
      if: always() && github.actor != 'nektos/act' && hashFiles('bandit-report.sarif') != ''
      continue-on-error: true  # Don't fail if Code Security is not enabled

    - name: Upload Bandit artifacts
      uses: actions/upload-artifact@v4
      with:
        name: bandit-reports
        path: |
          bandit-report.json
          bandit-report.txt
          bandit-reports/
        retention-days: 30
      if: always()

  safety-check:
    name: Safety - Python Dependencies
    runs-on: ubuntu-latest
    timeout-minutes: 10
    continue-on-error: true  # Allow pipeline to continue even if vulnerabilities found

    steps:
    - name: Checkout repository
      uses: actions/checkout@v5

    - name: Set up Python
      uses: actions/setup-python@v4
      with:
        python-version: ${{ env.PYTHON_VERSION }}

    - name: Install Safety
      run: |
        python -m pip install --upgrade pip
        pip install safety

    - name: Check Python dependencies for vulnerabilities
      run: |
        echo "🔒 Scanning Python dependencies for vulnerabilities..."
        mkdir -p safety-reports

        # Safety v3+ uses different syntax - check each requirements file
        find . -name "requirements.txt" -print0 | while IFS= read -r -d '' req_file; do
          echo "Checking: $req_file"
          # Use correct Safety v3 syntax
          safety check --requirements "$req_file" --output json > "safety-reports/safety-$(basename $(dirname "$req_file")).json" 2>/dev/null || true
          safety check --requirements "$req_file" --output text > "safety-reports/safety-$(basename $(dirname "$req_file")).txt" 2>/dev/null || true
        done

        # Generate overall scan
        safety check --output json > safety-reports/safety-combined.json 2>/dev/null || true
        safety check --output text > safety-reports/safety-combined.txt 2>/dev/null || true

        # Copy files to root for upload
        cp safety-reports/* . 2>/dev/null || true

        # Show what was generated
        echo "Generated files:"
        ls -la safety-reports/ || true
      continue-on-error: true

    - name: Upload Safety artifacts
      uses: actions/upload-artifact@v4
      with:
        name: safety-reports
        path: |
          safety-*.json
          safety-report.txt
          safety-reports/
        retention-days: 30
      if: always()

  terraform-security:
    name: Terraform Security - Checkov
    runs-on: ubuntu-latest
    timeout-minutes: 15
    continue-on-error: true  # Allow pipeline to continue even if security issues found

    steps:
    - name: Checkout repository
      uses: actions/checkout@v5

    - name: Set up Python
      uses: actions/setup-python@v4
      with:
        python-version: ${{ env.PYTHON_VERSION }}

    - name: Install Checkov
      run: |
        python -m pip install --upgrade pip
        pip install checkov

    - name: Run Checkov Infrastructure Security Scan
      run: |
        echo "🏗️ Scanning Terraform infrastructure for security issues..."
        mkdir -p checkov-reports

        # Run Checkov with explicit output files
        echo "Generating SARIF report..."
        checkov -d infrastructure/ --framework terraform --output sarif --output-file-path checkov-reports/checkov-terraform.sarif --quiet || true

        echo "Generating JSON report..."
        checkov -d infrastructure/ --framework terraform --output json --output-file-path checkov-reports/checkov-terraform.json --quiet || true

        echo "Generating CLI report..."
        checkov -d infrastructure/ --framework terraform --output cli --output-file-path checkov-reports/checkov-terraform.txt --quiet || true

        # Copy and verify files
        cp checkov-reports/* . 2>/dev/null || true

        echo "Generated Checkov files:"
        ls -la checkov-reports/

        # Show file sizes
        for f in checkov-reports/*; do
          if [ -f "$f" ]; then
            echo "File: $f - Size: $(wc -c < "$f") bytes"
          fi
        done
      continue-on-error: true

    - name: Upload Checkov SARIF
      uses: github/codeql-action/upload-sarif@v3
      with:
        sarif_file: checkov-terraform.sarif
      if: always() && github.actor != 'nektos/act' && hashFiles('checkov-terraform.sarif') != ''
      continue-on-error: true  # Don't fail if Code Security is not enabled

    - name: Upload Checkov artifacts
      uses: actions/upload-artifact@v4
      with:
        name: checkov-reports
        path: |
          checkov-terraform.json
          checkov-terraform.txt
          checkov-reports/
        retention-days: 30
      if: always()

  dockerfile-security:
    name: Dockerfile Security - Hadolint
    runs-on: ubuntu-latest
    timeout-minutes: 10
    continue-on-error: true  # Allow pipeline to continue even if security issues found

    steps:
    - name: Checkout repository
      uses: actions/checkout@v5

    - name: Install Hadolint
      run: |
        wget -O hadolint https://github.com/hadolint/hadolint/releases/latest/download/hadolint-Linux-x86_64
        chmod +x hadolint
        sudo mv hadolint /usr/local/bin/

    - name: Run Hadolint on all Dockerfiles
      run: |
        echo "🐳 Scanning Dockerfiles for security and best practices..."
        mkdir -p hadolint-reports
        find . -name "Dockerfile*" -type f | while read -r dockerfile; do
          echo "Scanning: $dockerfile"
          dir_name=$(dirname "$dockerfile" | sed 's|/|_|g' | sed 's|^_||')
          hadolint "$dockerfile" --format sarif > "hadolint-reports/hadolint-${dir_name}.sarif" 2>/dev/null || true
          hadolint "$dockerfile" --format json > "hadolint-reports/hadolint-${dir_name}.json" 2>/dev/null || true
          hadolint "$dockerfile" > "hadolint-reports/hadolint-${dir_name}.txt" 2>/dev/null || true
        done

        # Copy files to root for upload
        cp hadolint-reports/* . 2>/dev/null || true
      continue-on-error: true  # Continue even if Dockerfile issues are found

    - name: Upload Hadolint artifacts
      uses: actions/upload-artifact@v4
      with:
        name: hadolint-reports
        path: |
          hadolint-reports/
          hadolint-*.json
          hadolint-*.txt
        retention-days: 30
      if: always()

  secrets-detection:
    name: Secrets Detection - Gitleaks
    runs-on: ubuntu-latest
    timeout-minutes: 10
    continue-on-error: true  # Allow pipeline to continue even if secrets found

    steps:
    - name: Checkout repository
      uses: actions/checkout@v5
      with:
        fetch-depth: 0

    - name: Install Gitleaks
      run: |
        wget -O gitleaks.tar.gz https://github.com/gitleaks/gitleaks/releases/download/v8.28.0/gitleaks_8.28.0_linux_x64.tar.gz
        tar -xzf gitleaks.tar.gz
        sudo mv gitleaks /usr/local/bin/

    - name: Run Gitleaks Secrets Detection
      run: |
        echo "🔑 Scanning for secrets and credentials..."
        mkdir -p gitleaks-reports

        # Run Gitleaks with explicit outputs
        echo "Generating SARIF report..."
        gitleaks detect --source . --report-format sarif --report-path gitleaks-reports/gitleaks-report.sarif --exit-code 0 || true

        echo "Generating JSON report..."
        gitleaks detect --source . --report-format json --report-path gitleaks-reports/gitleaks-report.json --exit-code 0 || true

        # Copy and verify files
        cp gitleaks-reports/* . 2>/dev/null || true

        echo "Generated Gitleaks files:"
        ls -la gitleaks-reports/

        # Show findings count
        if [ -f "gitleaks-reports/gitleaks-report.json" ]; then
          echo "Gitleaks results:"
          if [ -s "gitleaks-reports/gitleaks-report.json" ]; then
            # Count findings in JSON
            python3 -c "import json; data=json.load(open('gitleaks-reports/gitleaks-report.json')); print(f'Found {len(data)} potential secrets')" 2>/dev/null || echo "Could not parse results"
          else
            echo "No secrets detected"
          fi
        fi
      continue-on-error: true

    - name: Upload Gitleaks SARIF
      uses: github/codeql-action/upload-sarif@v3
      with:
        sarif_file: gitleaks-report.sarif
      if: always() && github.actor != 'nektos/act' && hashFiles('gitleaks-report.sarif') != ''
      continue-on-error: true  # Don't fail if Code Security is not enabled

    - name: Upload Gitleaks artifacts
      uses: actions/upload-artifact@v4
      with:
        name: gitleaks-reports
        path: |
          gitleaks-report.json
          gitleaks-reports/
        retention-days: 30
      if: always()

  sast-summary:
    name: SAST Summary
    runs-on: ubuntu-latest
    needs: [codeql-analysis, opengrep-analysis, bandit-analysis, safety-check, terraform-security, dockerfile-security, secrets-detection]
    if: always()

    steps:
    - name: Download all artifacts
      uses: actions/download-artifact@v5

    - name: Create SAST Summary
      run: |
        echo "# SAST Security Analysis Summary" > sast-summary.md
        echo "" >> sast-summary.md
        echo "## Vulnerability Counts by Severity" >> sast-summary.md
        echo "" >> sast-summary.md

        # Enhanced table with vulnerability counts by severity
        echo "| Tool | Critical | High | Medium | Low | Total | Status |" >> sast-summary.md
        echo "|------|----------|------|--------|-----|-------|--------|" >> sast-summary.md

        # Install jq if not available (usually is in GitHub runners)
        if ! command -v jq >/dev/null 2>&1; then
          sudo apt-get update && sudo apt-get install -y jq
        fi

        # Function to parse SARIF files for vulnerability counts
        parse_sarif() {
          local file="$1"
          if [ -f "$file" ] && [ -s "$file" ]; then
            local crit=$(jq -r '.runs[]?.results[]? | select(.level == "error" or .properties?.severity == "critical" or (.properties?."security-severity"? and (.properties."security-severity" | tonumber) >= 9.0)) | .ruleId' "$file" 2>/dev/null | wc -l || echo 0)
            local high=$(jq -r '.runs[]?.results[]? | select(.level == "warning" or .properties?.severity == "high" or (.properties?."security-severity"? and (.properties."security-severity" | tonumber) >= 7.0 and (.properties."security-severity" | tonumber) < 9.0)) | .ruleId' "$file" 2>/dev/null | wc -l || echo 0)
            local med=$(jq -r '.runs[]?.results[]? | select(.properties?.severity == "medium" or (.properties?."security-severity"? and (.properties."security-severity" | tonumber) >= 4.0 and (.properties."security-severity" | tonumber) < 7.0)) | .ruleId' "$file" 2>/dev/null | wc -l || echo 0)
            local low=$(jq -r '.runs[]?.results[]? | select(.level == "note" or .properties?.severity == "low" or .properties?.severity == "info" or (.properties?."security-severity"? and (.properties."security-severity" | tonumber) < 4.0)) | .ruleId' "$file" 2>/dev/null | wc -l || echo 0)
            echo "$crit $high $med $low"
          else
            echo "0 0 0 0"
          fi
        }

        # Function to parse Bandit JSON format
        parse_bandit() {
          local file="$1"
          if [ -f "$file" ] && [ -s "$file" ]; then
            local crit=$(jq -r '.results[]? | select(.issue_severity == "HIGH") | .issue_severity' "$file" 2>/dev/null | wc -l || echo 0)
            local high=$(jq -r '.results[]? | select(.issue_severity == "MEDIUM") | .issue_severity' "$file" 2>/dev/null | wc -l || echo 0)
            local med=$(jq -r '.results[]? | select(.issue_severity == "LOW") | .issue_severity' "$file" 2>/dev/null | wc -l || echo 0)
            echo "$crit $high $med 0"
          else
            echo "0 0 0 0"
          fi
        }

        # Function to parse Safety JSON format
        parse_safety() {
          local file="$1"
          if [ -f "$file" ] && [ -s "$file" ]; then
            # Safety vulnerabilities are typically all high/critical
            local total=$(jq -r 'if type == "array" then length else (.vulnerabilities // [] | length) end' "$file" 2>/dev/null || echo 0)
            echo "$total 0 0 0"
          else
            echo "0 0 0 0"
          fi
        }

        # Function to parse Checkov JSON format
        parse_checkov() {
          local file="$1"
          if [ -f "$file" ] && [ -s "$file" ]; then
            local crit=$(jq -r '.results.failed_checks[]? | select(.severity == "CRITICAL") | .check_id' "$file" 2>/dev/null | wc -l || echo 0)
            local high=$(jq -r '.results.failed_checks[]? | select(.severity == "HIGH") | .check_id' "$file" 2>/dev/null | wc -l || echo 0)
            local med=$(jq -r '.results.failed_checks[]? | select(.severity == "MEDIUM") | .check_id' "$file" 2>/dev/null | wc -l || echo 0)
            local low=$(jq -r '.results.failed_checks[]? | select(.severity == "LOW" or .severity == "INFO") | .check_id' "$file" 2>/dev/null | wc -l || echo 0)
            echo "$crit $high $med $low"
          else
            echo "0 0 0 0"
          fi
        }

        # Function to parse Hadolint JSON format
        parse_hadolint() {
          local file="$1"
          if [ -f "$file" ] && [ -s "$file" ]; then
            local crit=0  # Hadolint doesn't typically have critical
            local high=$(jq -r '.[]? | select(.level == "error") | .code' "$file" 2>/dev/null | wc -l || echo 0)
            local med=$(jq -r '.[]? | select(.level == "warning") | .code' "$file" 2>/dev/null | wc -l || echo 0)
            local low=$(jq -r '.[]? | select(.level == "info" or .level == "style") | .code' "$file" 2>/dev/null | wc -l || echo 0)
            echo "$crit $high $med $low"
          else
            echo "0 0 0 0"
          fi
        }

        # Function to parse Gitleaks JSON format
        parse_gitleaks() {
          local file="$1"
          if [ -f "$file" ] && [ -s "$file" ]; then
            # All detected secrets are critical
            local crit=$(jq -r 'if type == "array" then length else 0 end' "$file" 2>/dev/null || echo 0)
            echo "$crit 0 0 0"
          else
            echo "0 0 0 0"
          fi
        }

        # Function to parse OpenGrep/Semgrep JSON format
        parse_opengrep() {
          local file="$1"
          if [ -f "$file" ] && [ -s "$file" ]; then
            local crit=$(jq -r '.results[]? | select(.extra.severity == "ERROR") | .check_id' "$file" 2>/dev/null | wc -l || echo 0)
            local high=$(jq -r '.results[]? | select(.extra.severity == "WARNING") | .check_id' "$file" 2>/dev/null | wc -l || echo 0)
            local med=$(jq -r '.results[]? | select(.extra.severity == "INFO") | .check_id' "$file" 2>/dev/null | wc -l || echo 0)
            local low=0
            echo "$crit $high $med $low"
          else
            echo "0 0 0 0"
          fi
        }

        # Parse CodeQL results (SARIF format) 
        codeql_file=$(find . -name "*codeql*.sarif" | head -1)
        if [ -n "$codeql_file" ]; then
          codeql_counts=$(parse_sarif "$codeql_file")
        else
          codeql_counts="0 0 0 0"
        fi
        read codeql_crit codeql_high codeql_med codeql_low <<< "$codeql_counts"
        codeql_total=$((codeql_crit + codeql_high + codeql_med + codeql_low))

        # Parse OpenGrep results
        opengrep_counts=$(parse_opengrep "opengrep-reports/opengrep.json")
        read opengrep_crit opengrep_high opengrep_med opengrep_low <<< "$opengrep_counts"
        opengrep_total=$((opengrep_crit + opengrep_high + opengrep_med + opengrep_low))

        # Parse Bandit results
        bandit_counts=$(parse_bandit "bandit-reports/bandit-report.json")
        read bandit_crit bandit_high bandit_med bandit_low <<< "$bandit_counts"
        bandit_total=$((bandit_crit + bandit_high + bandit_med + bandit_low))

        # Parse Safety results
        safety_file=$(find . -name "safety*.json" | head -1)
        if [ -n "$safety_file" ]; then
          safety_counts=$(parse_safety "$safety_file")
        else
          safety_counts="0 0 0 0"
        fi
        read safety_crit safety_high safety_med safety_low <<< "$safety_counts"
        safety_total=$((safety_crit + safety_high + safety_med + safety_low))

        # Parse Checkov results
        checkov_counts=$(parse_checkov "checkov-reports/checkov-terraform.json")
        read checkov_crit checkov_high checkov_med checkov_low <<< "$checkov_counts"
        checkov_total=$((checkov_crit + checkov_high + checkov_med + checkov_low))

        # Parse Hadolint results
        hadolint_file=$(find . -name "hadolint*.json" | head -1)
        if [ -n "$hadolint_file" ]; then
          hadolint_counts=$(parse_hadolint "$hadolint_file")
        else
          hadolint_counts="0 0 0 0"
        fi
        read hadolint_crit hadolint_high hadolint_med hadolint_low <<< "$hadolint_counts"
        hadolint_total=$((hadolint_crit + hadolint_high + hadolint_med + hadolint_low))

        # Parse Gitleaks results
        gitleaks_counts=$(parse_gitleaks "gitleaks-reports/gitleaks-report.json")
        read gitleaks_crit gitleaks_high gitleaks_med gitleaks_low <<< "$gitleaks_counts"
        gitleaks_total=$((gitleaks_crit + gitleaks_high + gitleaks_med + gitleaks_low))

        # Generate the enhanced table with actual vulnerability counts
        echo "| CodeQL | $codeql_crit | $codeql_high | $codeql_med | $codeql_low | $codeql_total | ${{ needs.codeql-analysis.result }} |" >> sast-summary.md
        echo "| OpenGrep | $opengrep_crit | $opengrep_high | $opengrep_med | $opengrep_low | $opengrep_total | ${{ needs.opengrep-analysis.result }} |" >> sast-summary.md
        echo "| Bandit | $bandit_crit | $bandit_high | $bandit_med | $bandit_low | $bandit_total | ${{ needs.bandit-analysis.result }} |" >> sast-summary.md
        echo "| Safety | $safety_crit | $safety_high | $safety_med | $safety_low | $safety_total | ${{ needs.safety-check.result }} |" >> sast-summary.md
        echo "| Checkov (Terraform) | $checkov_crit | $checkov_high | $checkov_med | $checkov_low | $checkov_total | ${{ needs.terraform-security.result }} |" >> sast-summary.md
        echo "| Hadolint (Docker) | $hadolint_crit | $hadolint_high | $hadolint_med | $hadolint_low | $hadolint_total | ${{ needs.dockerfile-security.result }} |" >> sast-summary.md
        echo "| Gitleaks (Secrets) | $gitleaks_crit | $gitleaks_high | $gitleaks_med | $gitleaks_low | $gitleaks_total | ${{ needs.secrets-detection.result }} |" >> sast-summary.md
        echo "" >> sast-summary.md

        # Calculate totals across all tools
        total_crit=$((codeql_crit + opengrep_crit + bandit_crit + safety_crit + checkov_crit + hadolint_crit + gitleaks_crit))
        total_high=$((codeql_high + opengrep_high + bandit_high + safety_high + checkov_high + hadolint_high + gitleaks_high))
        total_med=$((codeql_med + opengrep_med + bandit_med + safety_med + checkov_med + hadolint_med + gitleaks_med))
        total_low=$((codeql_low + opengrep_low + bandit_low + safety_low + checkov_low + hadolint_low + gitleaks_low))
        total_all=$((total_crit + total_high + total_med + total_low))

        echo "| **TOTAL** | **$total_crit** | **$total_high** | **$total_med** | **$total_low** | **$total_all** | - |" >> sast-summary.md
        echo "" >> sast-summary.md

        # Add priority recommendations based on actual vulnerability counts
        if [ $total_crit -gt 0 ]; then
          echo "## 🚨 CRITICAL PRIORITY" >> sast-summary.md
          echo "" >> sast-summary.md
          echo "**$total_crit critical vulnerabilities found!** These require immediate attention." >> sast-summary.md
          echo "" >> sast-summary.md
        fi

        if [ $total_high -gt 0 ]; then
          echo "## ⚠️ HIGH PRIORITY" >> sast-summary.md
          echo "" >> sast-summary.md
          echo "**$total_high high-severity vulnerabilities found.** Address these as soon as possible." >> sast-summary.md
          echo "" >> sast-summary.md
        fi

        if [ $total_all -eq 0 ]; then
          echo "## ✅ NO VULNERABILITIES DETECTED" >> sast-summary.md
          echo "" >> sast-summary.md
          echo "Great work! No security vulnerabilities were detected by the SAST tools." >> sast-summary.md
          echo "" >> sast-summary.md
        fi

        echo "## Security Reports Location" >> sast-summary.md
        echo "" >> sast-summary.md
        echo "🔍 **Security scan results are available in the following locations:**" >> sast-summary.md
        echo "" >> sast-summary.md
        echo "1. **Workflow Artifacts** - Download detailed reports from the Actions tab" >> sast-summary.md
        echo "2. **GitHub Security Tab** - If GitHub Advanced Security is enabled" >> sast-summary.md
        echo "3. **SARIF Files** - Available as artifacts for integration with other tools" >> sast-summary.md
        echo "" >> sast-summary.md
        echo "📋 **Available Report Formats:**" >> sast-summary.md
        echo "- SARIF (for security tools integration)" >> sast-summary.md
        echo "- JSON (for programmatic analysis)" >> sast-summary.md
        echo "- Text (for human-readable output)" >> sast-summary.md
        echo "" >> sast-summary.md

        echo "## Recommendations" >> sast-summary.md
        echo "" >> sast-summary.md
        echo "1. **Download artifacts** to review detailed security findings" >> sast-summary.md
        echo "2. **Address high and critical severity issues** first" >> sast-summary.md
        echo "3. **Update dependencies** with known vulnerabilities" >> sast-summary.md
        echo "4. **Implement security fixes** for infrastructure issues" >> sast-summary.md
        echo "5. **Consider enabling GitHub Advanced Security** for integrated security dashboard" >> sast-summary.md
        echo "" >> sast-summary.md

        echo "## GitHub Advanced Security" >> sast-summary.md
        echo "" >> sast-summary.md
        echo "ℹ️  **Note:** Some SARIF uploads may show warnings if GitHub Advanced Security is not enabled." >> sast-summary.md
        echo "This doesn't affect the security scanning - all results are still available as downloadable artifacts." >> sast-summary.md
        echo "" >> sast-summary.md
        echo "To enable Code Security features:" >> sast-summary.md
        echo "1. Go to repository Settings > Security & Analysis" >> sast-summary.md
        echo "2. Enable 'Private vulnerability reporting'" >> sast-summary.md
        echo "3. Enable 'Dependency review' (requires GitHub Advanced Security)" >> sast-summary.md
        echo "4. Enable 'Code scanning' (requires GitHub Advanced Security)" >> sast-summary.md
        echo "" >> sast-summary.md
        echo "Generated on: $(date)" >> sast-summary.md

    - name: Upload SAST Summary
      uses: actions/upload-artifact@v4
      with:
        name: sast-summary
        path: sast-summary.md
        retention-days: 30

    - name: Comment PR with SAST Results
      if: github.event_name == 'pull_request'
      uses: actions/github-script@v8
      continue-on-error: true  # Don't fail the workflow if commenting fails
      with:
        github-token: ${{ secrets.GITHUB_TOKEN }}
        script: |
          const fs = require('fs');
          
          // Check if we have the necessary permissions and context
          console.log('Repository:', context.repo.owner + '/' + context.repo.repo);
          console.log('Event name:', context.eventName);
          console.log('Actor:', context.actor);
          console.log('PR number:', context.issue?.number);
          console.log('Is from fork:', context.payload.pull_request?.head?.repo?.fork || false);
          
          // Check if running from a fork
          const isFromFork = context.payload.pull_request?.head?.repo?.fork || false;
          if (isFromFork) {
            console.log('⚠️  Running from a fork - PR commenting may be restricted');
          }
          
          try {
            const summary = fs.readFileSync('sast-summary.md', 'utf8');

            await github.rest.issues.createComment({
              issue_number: context.issue.number,
              owner: context.repo.owner,
              repo: context.repo.repo,
              body: summary
            });
            
            console.log('✅ Successfully posted SAST summary comment');
            core.setOutput('comment_posted', 'true');
          } catch (error) {
            console.log('❌ Failed to post SAST comment:', error.message);
            console.log('Error status:', error.status);
            
            if (error.status === 403) {
              console.log('🔒 Permission denied - this can happen when:');
              console.log('   • Running on a fork (security restriction)');
              console.log('   • Missing pull-requests: write permission');
              console.log('   • Repository settings restrict PR comments');
            } else if (error.status === 404) {
              console.log('🔍 Resource not found - check if PR exists');
            }
            
            console.log('📋 SAST report is still available in workflow artifacts');
            
            // Set step output to indicate comment failed
            core.setOutput('comment_posted', 'false');
            core.setOutput('comment_error', error.message);
          }
